const puppeteer = require("puppeteer");
const fs = require("fs");
const path = require("path");
const https = require("https");

/**
 * í…ŒìŠ¤íŠ¸ìš© ì—°ì˜ˆì¸ ë¦¬ìŠ¤íŠ¸ (ë‚¨ì„± 10ëª…, ì—¬ì„± 10ëª…)
 */
const CELEBRITIES = [
    // ë‚¨ì„± ì—°ì˜ˆì¸
    "ìœ ìž¬ì„", "ì§€ë“œëž˜ê³¤", "ì†í¥ë¯¼", "ì°¨ì€ìš°", "ê³µìœ ",
    "BTS ë·”", "ì´ë¯¼í˜¸", "ì •ìš°ì„±", "ë°•ì„œì¤€", "ì´ë³‘í—Œ",
    // ì—¬ì„± ì—°ì˜ˆì¸
    "ì•„ì´ìœ ", "ë¸”ëž™í•‘í¬ ì œë‹ˆ", "ìˆ˜ì§€", "ì†¡í˜œêµ", "ê¹€í˜œìˆ˜",
    "í•œì†Œí¬", "ê¹€íƒœë¦¬", "ì „ì§€í˜„", "ìž„ìœ¤ì•„", "ì—ìŠ¤íŒŒ ì¹´ë¦¬ë‚˜"
];

const DOWNLOAD_DIR = path.join(__dirname, "images");
const IMAGES_PER_PERSON = 10;

async function downloadImage(url, filepath) {
    return new Promise((resolve, reject) => {
        https.get(url, (res) => {
            if (res.statusCode === 200) {
                res.pipe(fs.createWriteStream(filepath))
                    .on("error", reject)
                    .on("close", resolve);
            } else {
                res.resume();
                reject(new Error(`Request Failed With Status Code: ${res.statusCode}`));
            }
        });
    });
}

async function scrapeImages() {
    if (!fs.existsSync(DOWNLOAD_DIR)) {
        fs.mkdirSync(DOWNLOAD_DIR);
    }

    const browser = await puppeteer.launch({
        headless: "new",
        args: ["--no-sandbox", "--disable-setuid-sandbox"]
    });

    const page = await browser.newPage();
    await page.setViewport({ width: 1280, height: 800 });

    for (const name of CELEBRITIES) {
        console.log(`\nðŸ”Ž Scraping images for: ${name}...`);
        const personDir = path.join(DOWNLOAD_DIR, name);
        if (!fs.existsSync(personDir)) {
            fs.mkdirSync(personDir);
        }

        try {
            // Google ì´ë¯¸ì§€ ê²€ìƒ‰
            const query = encodeURIComponent(`${name} ì–¼êµ´`);
            await page.goto(`https://www.google.com/search?q=${query}&tbm=isch`, {
                waitUntil: "networkidle2"
            });

            // ì´ë¯¸ì§€ URL ì¶”ì¶œ
            const imageUrls = await page.evaluate((maxCount) => {
                const imgs = Array.from(document.querySelectorAll('img'));
                return imgs
                    .map(img => img.src || img.dataset.src || img.dataset.iurl)
                    .filter(src => src && src.startsWith('http'))
                    .slice(0, maxCount);
            }, IMAGES_PER_PERSON);

            console.log(`  - Found ${imageUrls.length} potential image URLs`);

            for (let i = 0; i < imageUrls.length; i++) {
                const ext = imageUrls[i].includes("webp") ? "webp" : "jpg";
                const filepath = path.join(personDir, `${i + 1}.${ext}`);

                try {
                    await downloadImage(imageUrls[i], filepath);
                    console.log(`  - [${i + 1}/${imageUrls.length}] Downloaded`);
                } catch (err) {
                    console.error(`  - [${i + 1}] Skip (Error: ${err.message})`);
                }
            }
        } catch (error) {
            console.error(`âŒ Failed to scrape ${name}: ${error.message}`);
        }
    }

    await browser.close();
    console.log("\nâœ… Scraping Completed!");
}

scrapeImages();
